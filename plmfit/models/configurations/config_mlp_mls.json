{ "architecture":{
  "network_type": "mlp",
  "layers": [
    {"type": "linear", "input_len": 1024, "output_len": 1024, "activation_function": "relu"},
    {"type": "dropout", "rate": 0.5},
    {"type": "linear", "input_len": 1024, "output_len": 1}]
},
  "training":{
    "learning_rate": 0.0001,
    "loss_function": "combined_bce_loss",
    "batch_size": 1000,
    "epochs":10,
    "optimizer": "adam"
}
}
