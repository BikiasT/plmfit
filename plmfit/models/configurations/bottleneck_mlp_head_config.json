{
  "architecture_parameters": {
    "network_type": "mlp",
    "output_dim": 1,
    "hidden_dim": 1024,
    "task": "regression",
    "hidden_activation": "relu",
    "hidden_dropout": 0.25
  },
  "training_parameters": {
    "learning_rate": 0.0001,
    "epochs": 3,
    "batch_size": 4,
    "loss_f": "mse",
    "optimizer": "adam",
    "val_split": 0.2,
    "weight_decay": 0.0001,
    "warmup_steps": 0,
    "gradient_clipping": false,
    "scheduler": false,
    "scaler": false,
    "gradient_accumulation": 2,
    "early_stopping": 2,
    "epoch_sizing": 30000,
    "model_output": "logits"
  }
}
