{
  "architecture_parameters":
  {
    "network_type": "mlp",
    "output_dim": 1,
    "hidden_dim": 1024,
    "task": "regression",
    "hidden_activation": "relu",
    "hidden_dropout": 0.25
  },
  "training_parameters":
  {
    "learning_rate": 0.0001,
    "epochs": 200,
    "batch_size": 128,
    "loss_f": "mse",
    "optimizer": "adam",
    "val_split": 0.2,
    "weight_decay": 0.01,
    "warmup_steps": 0,
    "gradient_clipping": false,
    "scheduler": false,
    "scaler": false,
    "gradient_accumulation": false,
    "early_stopping": true
  }
}
